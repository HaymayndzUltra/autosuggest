import {
  BrowserWindow,
  app,
  ipcMain,
  desktopCapturer,
  session,
} from "electron";
// This allows TypeScript to pick up the magic constants that's auto-generated by Forge's Webpack
// plugin that tells the Electron app where to look for the Webpack-bundled app code (depending on
// whether you're running in development or production).
declare const MAIN_WINDOW_WEBPACK_ENTRY: string;
declare const MAIN_WINDOW_PRELOAD_WEBPACK_ENTRY: string;
import Prism from "prismjs";
import OpenAI from "openai";
import axios from "axios";
import FormData from "form-data";
import fs, { FSWatcher } from "fs";
import path from "path";
import { Buffer } from "buffer";
import { spawn } from 'child_process';
import { createClient, LiveTranscriptionEvents } from "@deepgram/sdk";
import { ASRHealthChecker } from './utils/asrHealthCheck';
import { ASRProviderController } from './utils/providerController';
import { LocalASRClient } from './utils/localASRClient';
import { MetricsLogger } from './utils/metricsLogger';

// Handle creating/removing shortcuts on Windows when installing/uninstalling.
import electronSquirrelStartup from "electron-squirrel-startup";

if (electronSquirrelStartup) {
  app.quit();
}

type ContextFileKey =
  | "resume"
  | "jobPost"
  | "discoveryQuestions"
  | "skillsKnowledge"
  | "workflowMethod";

type PromptFileKey = "behaviorRules" | "languageGuide" | "responseStyle";

interface WatchedFileStatus {
  exists: boolean;
  hasContent: boolean;
  path: string;
  lastUpdated: number;
  error?: string;
}

interface ContextFileResult {
  data: Record<ContextFileKey, string>;
  status: Record<ContextFileKey, WatchedFileStatus>;
}

interface PromptFileResult {
  data: Record<PromptFileKey, string>;
  status: Record<PromptFileKey, WatchedFileStatus>;
}

const CONTEXT_FILE_MAPPINGS: { key: ContextFileKey; filename: string }[] = [
  { key: "resume", filename: "resume.md" },
  { key: "jobPost", filename: "current_job.md" },
  { key: "discoveryQuestions", filename: "discovery_questions.md" },
  { key: "skillsKnowledge", filename: "skills_knowledge.md" },
  { key: "workflowMethod", filename: "workflow_method.md" },
];

const PROMPT_FILE_MAPPINGS: { key: PromptFileKey; filename: string }[] = [
  { key: "behaviorRules", filename: "behavior_rules.md" },
  { key: "languageGuide", filename: "language_guide.md" },
  { key: "responseStyle", filename: "response_style.md" },
];

let mainWindow: BrowserWindow | null = null;
let contextWatcher: FSWatcher | null = null;
let promptWatcher: FSWatcher | null = null;

// ASR Provider state
let activeASRProvider: 'local' | 'deepgram' | null = null;
let localASRFailureCount = 0;
let lastLocalASRFailureTime: number | null = null;
let localASRClient: LocalASRClient | null = null;
let metricsLogger: MetricsLogger;

const readContextFiles = (): ContextFileResult => {
  const contextDir = path.join(__dirname, "..", "context");
  const data: Record<ContextFileKey, string> = {
    resume: "",
    jobPost: "",
    discoveryQuestions: "",
    skillsKnowledge: "",
    workflowMethod: "",
  };
  const status = CONTEXT_FILE_MAPPINGS.reduce<Record<ContextFileKey, WatchedFileStatus>>(
    (acc, mapping) => {
      const filePath = path.join(contextDir, mapping.filename);
      const baseStatus: WatchedFileStatus = {
        exists: false,
        hasContent: false,
        path: filePath,
        lastUpdated: Date.now(),
      };

      if (fs.existsSync(filePath)) {
        try {
          const content = fs.readFileSync(filePath, "utf8");
          data[mapping.key] = content;
          acc[mapping.key] = {
            ...baseStatus,
            exists: true,
            hasContent: content.trim().length > 0,
          };
        } catch (error) {
          acc[mapping.key] = {
            ...baseStatus,
            exists: true,
            error: error instanceof Error ? error.message : String(error),
          };
        }
      } else {
        acc[mapping.key] = {
          ...baseStatus,
          error: "File not found",
        };
      }

      return acc;
    },
    {
      resume: {
        exists: false,
        hasContent: false,
        path: path.join(contextDir, "resume.md"),
        lastUpdated: Date.now(),
      },
      jobPost: {
        exists: false,
        hasContent: false,
        path: path.join(contextDir, "current_job.md"),
        lastUpdated: Date.now(),
      },
      discoveryQuestions: {
        exists: false,
        hasContent: false,
        path: path.join(contextDir, "discovery_questions.md"),
        lastUpdated: Date.now(),
      },
      skillsKnowledge: {
        exists: false,
        hasContent: false,
        path: path.join(contextDir, "skills_knowledge.md"),
        lastUpdated: Date.now(),
      },
      workflowMethod: {
        exists: false,
        hasContent: false,
        path: path.join(contextDir, "workflow_method.md"),
        lastUpdated: Date.now(),
      },
    }
  );

  return { data, status };
};

const readPromptFiles = (): PromptFileResult => {
  const promptsDir = path.join(__dirname, "..", "prompts");
  const data: Record<PromptFileKey, string> = {
    behaviorRules: "",
    languageGuide: "",
    responseStyle: "",
  };

  const status = PROMPT_FILE_MAPPINGS.reduce<Record<PromptFileKey, WatchedFileStatus>>(
    (acc, mapping) => {
      const filePath = path.join(promptsDir, mapping.filename);
      const baseStatus: WatchedFileStatus = {
        exists: false,
        hasContent: false,
        path: filePath,
        lastUpdated: Date.now(),
      };

      if (fs.existsSync(filePath)) {
        try {
          const content = fs.readFileSync(filePath, "utf8");
          data[mapping.key] = content;
          acc[mapping.key] = {
            ...baseStatus,
            exists: true,
            hasContent: content.trim().length > 0,
          };
        } catch (error) {
          acc[mapping.key] = {
            ...baseStatus,
            exists: true,
            error: error instanceof Error ? error.message : String(error),
          };
        }
      } else {
        acc[mapping.key] = {
          ...baseStatus,
          error: "File not found",
        };
      }

      return acc;
    },
    {
      behaviorRules: {
        exists: false,
        hasContent: false,
        path: path.join(promptsDir, "behavior_rules.md"),
        lastUpdated: Date.now(),
      },
      languageGuide: {
        exists: false,
        hasContent: false,
        path: path.join(promptsDir, "language_guide.md"),
        lastUpdated: Date.now(),
      },
      responseStyle: {
        exists: false,
        hasContent: false,
        path: path.join(promptsDir, "response_style.md"),
        lastUpdated: Date.now(),
      },
    }
  );

  return { data, status };
};

const notifyContextUpdate = (): ContextFileResult => {
  const result = readContextFiles();
  if (mainWindow && !mainWindow.isDestroyed()) {
    mainWindow.webContents.send("context-files-updated", result);
  }
  return result;
};

const notifyPromptUpdate = (): PromptFileResult => {
  const result = readPromptFiles();
  if (mainWindow && !mainWindow.isDestroyed()) {
    mainWindow.webContents.send("prompt-files-updated", result);
  }
  return result;
};

const setupFileWatchers = () => {
  const contextDir = path.join(__dirname, "..", "context");
  const promptsDir = path.join(__dirname, "..", "prompts");

  if (contextWatcher) {
    contextWatcher.close();
  }
  if (promptWatcher) {
    promptWatcher.close();
  }

  if (fs.existsSync(contextDir)) {
    contextWatcher = fs.watch(contextDir, (eventType, filename) => {
      if (!filename || !filename.endsWith(".md")) {
        return;
      }
      notifyContextUpdate();
    });
  } else {
    notifyContextUpdate();
  }

  if (fs.existsSync(promptsDir)) {
    promptWatcher = fs.watch(promptsDir, (eventType, filename) => {
      if (!filename || !filename.endsWith(".md")) {
        return;
      }
      notifyPromptUpdate();
    });
  } else {
    notifyPromptUpdate();
  }
};

// Auto-start local ASR on app launch
const startLocalASR = () => {
  const scriptPath = path.join(__dirname, '..', 'scripts', 'start-local-asr.bat');
  
  console.log('🚀 Starting Local ASR service...');
  
  const process = spawn(scriptPath, [], {
    detached: true,
    stdio: 'ignore',
    shell: true,
  });
  
  process.unref(); // Don't wait for the process
  
  console.log('✅ Local ASR startup initiated');
};

const createWindow = (): void => {
  // Initialize metrics logger
  metricsLogger = MetricsLogger.getInstance();
  
  mainWindow = new BrowserWindow({
    height: 1000,
    width: 1300,
    webPreferences: {
      preload: MAIN_WINDOW_PRELOAD_WEBPACK_ENTRY,
      contextIsolation: true,
      nodeIntegration: false,
      webSecurity: false,
    },
  });

  mainWindow.webContents.session.webRequest.onHeadersReceived(
    (details, callback) => {
      callback({
        responseHeaders: {
          ...details.responseHeaders,
          "Content-Security-Policy": [
            "default-src 'self' 'unsafe-inline' 'unsafe-eval' data: blob:; script-src 'self' 'unsafe-inline' 'unsafe-eval' blob:; connect-src 'self' https://api.openai.com http://127.0.0.1:* http://localhost:* ws: wss:;",
          ],
        },
      });
    }
  );

  mainWindow.webContents.session.setPermissionRequestHandler(
    (webContents, permission, callback) => {
      if (permission === "media") {
        callback(true);
      } else {
        callback(false);
      }
    }
  );

  mainWindow.loadURL(MAIN_WINDOW_WEBPACK_ENTRY + "#/main_window");
//  mainWindow.webContents.openDevTools();

  mainWindow.webContents.on("did-finish-load", () => {
    mainWindow?.webContents.executeJavaScript(`
      console.log('Applied CSP:', document.querySelector('meta[http-equiv="Content-Security-Policy"]')?.getAttribute('content'));
    `);
    notifyContextUpdate();
    notifyPromptUpdate();
  });

  setupFileWatchers();

  mainWindow.on("closed", () => {
    mainWindow = null;
  });
};

ipcMain.handle(
  "save-temp-audio-file",
  async (event, audioBuffer: ArrayBuffer) => {
    try {
      const tempFilePath = path.join(
        app.getPath("temp"),
        `temp_audio_${Date.now()}.wav`
      );
      fs.writeFileSync(tempFilePath, Buffer.from(audioBuffer));
      return tempFilePath;
    } catch (error) {
      throw error;
    }
  }
);

ipcMain.handle(
  "transcribe-audio-file",
  async (event, filePath: string, config) => {
    try {
      const formData = new FormData();
      formData.append("file", fs.createReadStream(filePath), "audio.wav");
      formData.append("model", "whisper-1");

      if (config.primaryLanguage && config.primaryLanguage !== "auto") {
        formData.append("language", config.primaryLanguage);
      }
      if (config.secondaryLanguage) {
        formData.append(
          "prompt",
          `This audio may contain ${config.primaryLanguage} and ${config.secondaryLanguage}.`
        );
      }

      const baseUrl = normalizeApiBaseUrl(config.api_base);
      const apiUrl = `${baseUrl}/audio/transcriptions`;
      const response = await axios.post(apiUrl, formData, {
        headers: {
          ...formData.getHeaders(),
          Authorization: `Bearer ${config.openai_key}`,
        },
        maxContentLength: Infinity,
        maxBodyLength: Infinity,
      });

      return response.data;
    } catch (error) {
      throw error;
    } finally {
      fs.unlinkSync(filePath);
    }
  }
);

// This method will be called when Electron has finished
// initialization and is ready to create browser windows.
// Some APIs can only be used after this event occurs.
app.on("ready", () => {
  // Try to start local ASR (non-blocking)
  try {
    startLocalASR();
  } catch (error) {
    console.warn('⚠️ Failed to auto-start Local ASR:', error);
  }
  
  createWindow();
});

// Quit when all windows are closed, except on macOS. There, it's common
// for applications and their menu bar to stay active until the
// dock icon is clicked and there are no other windows open.
app.on("window-all-closed", () => {
  if (process.platform !== "darwin") {
    app.quit();
  }
});

app.on("activate", () => {
  // On OS X it's common to re-create a window in the app when the
  // dock icon is clicked and there are no other windows open.
  if (BrowserWindow.getAllWindows().length === 0) {
    createWindow();
  }
});

// In this file you can include the rest of your app's specific main process
// code. You can also put them in separate files and import them here.

import ElectronStore from "electron-store";

interface StoreSchema {
  config: Record<string, any>;
}

type TypedElectronStore = ElectronStore<StoreSchema> & {
  get: <K extends keyof StoreSchema>(key: K) => StoreSchema[K];
  set: <K extends keyof StoreSchema>(key: K, value: StoreSchema[K]) => void;
  clear: () => void;
};

const store = new ElectronStore<StoreSchema>() as TypedElectronStore;

ipcMain.handle("get-config", () => {
  return store.get("config");
});

ipcMain.handle("set-config", (event, config) => {
  store.set("config", config);
});

ipcMain.handle("parsePDF", async (event, pdfBuffer) => {
  try {
    const pdf = require("pdf-parse");
    const data = await pdf(Buffer.from(pdfBuffer), {
      max: 0,
    });
    return { text: data.text };
  } catch (error) {
    return { error: "Failed to parse PDF: " + error.message };
  }
});

ipcMain.handle("process-image", async (event, imageData) => {
  try {
    const sharp = require("sharp");
    let image;
    if (imageData.startsWith("data:image")) {
      const base64Data = imageData.split(",")[1];
      const imageBuffer = Buffer.from(base64Data, "base64");
      image = sharp(imageBuffer);
    } else {
      throw new Error(
        "Invalid image input: expected Base64 encoded image data"
      );
    }
    const metadata = await image.metadata();
    return `Image size: ${metadata.width}x${metadata.height}, Format: ${metadata.format}`;
  } catch (error) {
    return { error: "Failed to process image: " + error.message };
  }
});

ipcMain.handle("highlightCode", async (event, code, language) => {
  return Prism.highlight(code, Prism.languages[language], language);
});

app.on("before-quit", () => {
  const config = store.get("config") || {};
  const apiInfo = {
    openai_key: config.openai_key || "",
    api_base: config.api_base || "",
    gpt_model: config.gpt_model || "",
    api_call_method: config.api_call_method || "direct",
    primaryLanguage: config.primaryLanguage || "en",
    deepgram_api_key: config.deepgram_api_key || "",
    asr_provider: config.asr_provider || "auto",
    local_asr_url: config.local_asr_url || "http://127.0.0.1:9001",
  };
  store.clear();
  store.set("config", apiInfo);
});

ipcMain.handle("get-system-audio-stream", async () => {
  try {
    const sources = await desktopCapturer.getSources({
      types: ["window", "screen"],
      fetchWindowIcons: false,
    });
    const audioSources = sources.filter(
      (source) =>
        source.name.toLowerCase().includes("sound") ||
        source.name.toLowerCase().includes("audio")
    );
    return audioSources.map((source) => source.id);
  } catch (error) {
    throw error;
  }
});

app.on("ready", () => {
  session.defaultSession.setDisplayMediaRequestHandler(
    (request, callback) => {
      desktopCapturer.getSources({ types: ["screen"] }).then((sources) => {
        callback({ video: sources[0], audio: "loopback" });
      });
    },
    { useSystemPicker: true }
  );

  ipcMain.handle(
    "transcribe-audio",
    async (event, audioBuffer: ArrayBuffer, config) => {
      try {
        const tempFilePath = path.join(
          app.getPath("temp"),
          `temp_audio_${Date.now()}.wav`
        );
        fs.writeFileSync(tempFilePath, Buffer.from(audioBuffer));

        const formData = new FormData();
        formData.append("file", fs.createReadStream(tempFilePath), {
          filename: "audio.wav",
          contentType: "audio/wav",
        });
        formData.append("model", "whisper-1");

        if (config.primaryLanguage && config.primaryLanguage !== "auto") {
          formData.append("language", config.primaryLanguage);
        }
        if (config.secondaryLanguage) {
          formData.append(
            "prompt",
            `This audio may contain ${config.primaryLanguage} and ${config.secondaryLanguage}.`
          );
        }

        const baseUrl = normalizeApiBaseUrl(config.api_base);
        const apiUrl = `${baseUrl}/audio/transcriptions`;
        const response = await axios.post(apiUrl, formData, {
          headers: {
            ...formData.getHeaders(),
            Authorization: `Bearer ${config.openai_key}`,
          },
          maxContentLength: Infinity,
          maxBodyLength: Infinity,
        });

        fs.unlinkSync(tempFilePath);

        return response.data;
      } catch (error) {
        throw error;
      }
    }
  );
});

ipcMain.handle("test-api-config", async (event, config) => {
  try {
    const axiosInstance = axios.create({
      baseURL: normalizeApiBaseUrl(config.api_base),
      headers: {
        Authorization: `Bearer ${config.openai_key}`,
        "Content-Type": "application/json",
      },
    });

    const response = await axiosInstance.post("/chat/completions", {
      model: config.gpt_model || "gpt-3.5-turbo",
      messages: [{ role: "user", content: "Hello, this is a test." }],
    });

    if (
      response.data.choices &&
      response.data.choices[0] &&
      response.data.choices[0].message
    ) {
      return { success: true };
    } else {
      return { success: false, error: "Unexpected API response structure" };
    }
  } catch (error) {
    if (axios.isAxiosError(error)) {
      if (error.response) {
        return {
          success: false,
          error: `Server responded with error: ${error.response.status} ${error.response.statusText}`,
        };
      } else if (error.request) {
        return {
          success: false,
          error:
            "No response received from server. Please check your network connection and API base URL.",
        };
      } else {
        return {
          success: false,
          error: `Error setting up the request: ${error.message}`,
        };
      }
    }
    return {
      success: false,
      error: error instanceof Error ? error.message : "Unknown error occurred",
    };
  }
});

ipcMain.handle("callOpenAI", async (event, { config, messages, signal }) => {
  try {
    const openai = new OpenAI({
      apiKey: config.openai_key,
      baseURL: normalizeApiBaseUrl(config.api_base),
    });

    const abortController = new AbortController();
    if (signal) {
      signal.addEventListener('abort', () => abortController.abort());
    }

    const response = await openai.chat.completions.create({
      model: config.gpt_model || "gpt-3.5-turbo",
      messages: messages,
    }, { signal: abortController.signal });

    if (
      !response.choices ||
      !response.choices[0] ||
      !response.choices[0].message
    ) {
      throw new Error("Unexpected API response structure");
    }
    return { content: response.choices[0].message.content };
  } catch (error) {
    if (error.name === "AbortError") {
      return { error: "AbortError" };
    }
    return { error: error.message || "Unknown error occurred" };
  }
});

ipcMain.handle("callOpenAIStream", async (event, { config, messages }) => {
  try {
    const openai = new OpenAI({
      apiKey: config.openai_key,
      baseURL: normalizeApiBaseUrl(config.api_base),
    });

    const stream = await openai.chat.completions.create({
      model: config.gpt_model || "gpt-3.5-turbo",
      messages: messages,
      temperature: config.temperature || 0.7,
      max_tokens: config.max_tokens || 2000,
      stream: true,
    });

    for await (const chunk of stream) {
      const content = chunk.choices[0]?.delta?.content || "";
      if (content) {
        event.sender.send('openai-stream-chunk', { content, done: false });
      }
    }
    
    // Send completion signal
    event.sender.send('openai-stream-chunk', { content: "", done: true });
    
    return { success: true };
  } catch (error) {
    event.sender.send('openai-stream-chunk', { content: "", done: true, error: error.message });
    return { error: error.message };
  }
});

ipcMain.handle("get-desktop-sources", async () => {
  try {
    const sources = await desktopCapturer.getSources({
      types: ["window", "screen"],
    });
    return sources.map((source) => ({
      id: source.id,
      name: source.name,
      thumbnail: source.thumbnail.toDataURL(),
    }));
  } catch (error) {
    return [];
  }
});

function normalizeApiBaseUrl(url: string): string {
  if (!url) return "https://api.openai.com/v1";
  url = url.trim();
  if (!url.startsWith("http://") && !url.startsWith("https://")) {
    url = "https://" + url;
  }
  if (!url.endsWith("/v1")) {
    url = url.endsWith("/") ? url + "v1" : url + "/v1";
  }
  return url;
}

let deepgramConnection: any = null;

/**
 * Switch ASR provider and notify renderer
 */
const switchASRProvider = async (newProvider: 'local' | 'deepgram' | null, reason: 'timeout' | 'errors' | 'manual' | 'health_check') => {
  const fromProvider = activeASRProvider;
  const switchStartTime = Date.now();
  activeASRProvider = newProvider;
  
  console.log(`🔄 ASR Provider switched: ${fromProvider} → ${newProvider} (${reason})`);
  
  // Log metrics
  if (metricsLogger) {
    const switchLatency = Date.now() - switchStartTime;
    metricsLogger.logProviderSwitch(fromProvider, newProvider, reason, switchLatency);
  }
  
  // Notify renderer of provider change
  if (mainWindow && !mainWindow.isDestroyed()) {
    mainWindow.webContents.send('asr-provider-changed', {
      from: fromProvider,
      to: newProvider,
      reason,
      timestamp: Date.now(),
    });
  }
  
  // Reset failure counters when switching
  if (newProvider === 'local') {
    localASRFailureCount = 0;
    lastLocalASRFailureTime = null;
  }
};

/**
 * Handle local ASR failure and potentially switch to Deepgram
 */
const handleLocalASRFailure = async (config: any) => {
  localASRFailureCount++;
  lastLocalASRFailureTime = Date.now();
  
  console.log(`❌ Local ASR failure #${localASRFailureCount}`);
  
  // Check if we should failover to Deepgram
  if (ASRProviderController.shouldFailoverToDeepgram(
    localASRFailureCount,
    !!config.deepgram_api_key,
    lastLocalASRFailureTime
  )) {
    await switchASRProvider('deepgram', 'errors');
    
    // Start Deepgram if not already running
    if (!deepgramConnection) {
      try {
        const result = await startDeepgramConnection(config.deepgram_api_key);
        if (!result.success) {
          console.error('Failed to start Deepgram after failover:', result.error);
        }
      } catch (error) {
        console.error('Error starting Deepgram after failover:', error);
      }
    }
  }
};

/**
 * Handle Deepgram failure and potentially switch back to local
 */
const handleDeepgramFailure = async (config: any) => {
  console.log('❌ Deepgram connection failed');
  
  // Check if we should switch back to local
  const localHealth = await ASRHealthChecker.checkLocalASR(config.local_asr_url || 'http://127.0.0.1:9001');
  
  if (ASRProviderController.shouldSwitchBackToLocal(localHealth, 'Deepgram connection lost')) {
    await switchASRProvider('local', 'health_check');
  } else {
    // Neither provider available
    await switchASRProvider(null, 'errors');
  }
};
/**
 * Start Deepgram connection (reusable function)
 */
const startDeepgramConnection = async (deepgramKey: string): Promise<{ success: boolean, error?: string }> => {
  try {
    if (!deepgramKey) {
      throw new Error("Deepgram API key missing");
    }
    
    const deepgram = createClient(deepgramKey);
    deepgramConnection = deepgram.listen.live({
      punctuate: true,
      interim_results: true,
      model: "nova-2",
      language: "en",
      encoding: "linear16",
      sample_rate: 16000,
      endpointing: 6000, // Increased from 3000ms for better continuity
      vad_events: true, // Voice Activity Detection
      filler_words: true, // Capture natural speech patterns
      utterance_end_ms: 1000, // Quick finalization after brief pause
      smart_format: true,
    });

    deepgramConnection.addListener(LiveTranscriptionEvents.Open, () => {
      if (mainWindow && !mainWindow.isDestroyed()) {
        mainWindow.webContents.send("deepgram-status", { status: "open" });
      }
    });

    deepgramConnection.addListener(LiveTranscriptionEvents.Close, () => {
      if (mainWindow && !mainWindow.isDestroyed()) {
        mainWindow.webContents.send("deepgram-status", { status: "closed" });
      }
    });

    deepgramConnection.addListener(
      LiveTranscriptionEvents.Transcript,
      (data: any) => {
        if (
          data &&
          data.is_final &&
          data.channel &&
          data.channel.alternatives &&
          data.channel.alternatives[0]
        ) {
          const transcript = data.channel.alternatives[0].transcript;
          if (transcript && mainWindow && !mainWindow.isDestroyed()) {
            mainWindow.webContents.send("deepgram-transcript", {
              transcript,
              is_final: true,
              provider: 'deepgram',
            });
          }
        }
      }
    );

    deepgramConnection.addListener(
      LiveTranscriptionEvents.Error,
      (err: any) => {
        console.error('Deepgram error:', err);
        if (mainWindow && !mainWindow.isDestroyed()) {
          mainWindow.webContents.send("deepgram-error", err);
        }
        // Handle Deepgram failure for failover
        const config = store.get("config") || {};
        handleDeepgramFailure(config);
      }
    );

    await new Promise((resolve, reject) => {
      deepgramConnection.addListener(LiveTranscriptionEvents.Open, resolve);
      deepgramConnection.addListener(LiveTranscriptionEvents.Error, reject);
      setTimeout(() => reject(new Error("Deepgram timeout")), 10000);
    });

    return { success: true };
  } catch (error) {
    return { success: false, error: error instanceof Error ? error.message : String(error) };
  }
};

ipcMain.handle("start-deepgram", async (event, config) => {
  return await startDeepgramConnection(config.deepgram_key);
});

ipcMain.handle("start-asr", async (event, config) => {
  try {
    // Get health status
    const healthStatus = await ASRHealthChecker.checkBothProviders({
      local_asr_url: config.local_asr_url,
      deepgram_api_key: config.deepgram_api_key,
    });
    
    const hasDeepgramKey = !!(config.deepgram_api_key && config.deepgram_api_key.trim());
    const asrMode = config.asr_provider || 'auto';
    
    // Select provider
    const selectedProvider = ASRProviderController.selectProvider(
      asrMode,
      healthStatus.local,
      hasDeepgramKey
    );
    
    if (!selectedProvider) {
      return { success: false, error: 'No ASR provider available' };
    }
    
    // Set active provider
    activeASRProvider = selectedProvider;
    
    // Start the selected provider
    let result;
    if (selectedProvider === 'local') {
      result = await startLocalASRConnection(config);
    } else {
      result = await startDeepgramConnection(config.deepgram_api_key);
    }
    
    if (result.success) {
      console.log(`✅ Started ${selectedProvider} ASR successfully`);
    }
    
    return result;
  } catch (error) {
    console.error('Failed to start ASR:', error);
    return { 
      success: false, 
      error: error instanceof Error ? error.message : String(error) 
    };
  }
});

const startLocalASRConnection = async (config: any): Promise<{ success: boolean, error?: string }> => {
  try {
    const localUrl = config.local_asr_url || 'http://127.0.0.1:9001';
    
    // Create and connect to local ASR client
    localASRClient = new LocalASRClient(localUrl);
    await localASRClient.connect();
    
    console.log('✅ Local ASR started successfully');
    return { success: true };
  } catch (error) {
    console.error('❌ Failed to start local ASR:', error);
    return { 
      success: false, 
      error: error instanceof Error ? error.message : String(error) 
    };
  }
};

ipcMain.handle("send-audio-to-deepgram", async (event, audioData) => {
  // Route audio based on active provider
  if (activeASRProvider === 'local' && localASRClient) {
    try {
      await localASRClient.sendAudioChunk(audioData);
    } catch (error) {
      console.error('❌ Failed to send audio to local ASR:', error);
      // Handle local ASR failure
      const config = await store.get("config") || {};
      await handleLocalASRFailure(config);
    }
  } else if (activeASRProvider === 'deepgram' && deepgramConnection) {
    try {
      const buffer = Buffer.from(audioData);
      deepgramConnection.send(buffer);
    } catch (error) {
      console.error("❌ Failed to send data to Deepgram:", error);
      // Handle Deepgram failure
      const config = await store.get("config") || {};
      await handleDeepgramFailure(config);
    }
  } else {
    console.warn('⚠️ No active ASR provider or connection not ready');
  }
});

ipcMain.handle("stop-deepgram", () => {
  if (deepgramConnection) {
    deepgramConnection.finish();
    deepgramConnection = null;
  }
  if (localASRClient) {
    localASRClient.disconnect();
    localASRClient = null;
  }
  activeASRProvider = null;
});

// Handle local ASR transcript events
ipcMain.handle("local-asr-transcript", async (event, transcriptData) => {
  if (mainWindow && !mainWindow.isDestroyed()) {
    mainWindow.webContents.send("deepgram-transcript", transcriptData);
  }
});

// Handle local ASR failures
ipcMain.handle("local-asr-failure", async (event, failureData) => {
  console.log('❌ Local ASR failure reported:', failureData);
  const config = await store.get("config") || {};
  await handleLocalASRFailure(config);
});

// IPC handlers for loading context and prompt files
ipcMain.handle("load-context-files", async () => {
  try {
    return readContextFiles();
  } catch (error) {
    console.error("Failed to load context files:", error);
    return notifyContextUpdate();
  }
});

ipcMain.handle("load-prompt-files", async () => {
  try {
    return readPromptFiles();
  } catch (error) {
    console.error("Failed to load prompt files:", error);
    return notifyPromptUpdate();
  }
});

ipcMain.handle("export-metrics", async () => {
  try {
    if (metricsLogger) {
      return { success: true, data: metricsLogger.exportSessionLog() };
    } else {
      return { success: false, error: 'Metrics logger not initialized' };
    }
  } catch (error) {
    return { success: false, error: error instanceof Error ? error.message : 'Unknown error' };
  }
});

ipcMain.handle("get-metrics-summary", async () => {
  try {
    if (metricsLogger) {
      return { success: true, data: metricsLogger.getSessionSummary() };
    } else {
      return { success: false, error: 'Metrics logger not initialized' };
    }
  } catch (error) {
    return { success: false, error: error instanceof Error ? error.message : 'Unknown error' };
  }
});

ipcMain.handle("check-asr-health", async (event, config) => {
  try {
    console.log('🔍 Checking ASR health for providers...');
    const healthStatus = await ASRHealthChecker.checkBothProviders({
      local_asr_url: config.local_asr_url,
      deepgram_api_key: config.deepgram_api_key,
    });
    
    console.log('✅ ASR health check completed:', {
      local: healthStatus.local.healthy ? 'healthy' : 'unhealthy',
      deepgram: healthStatus.deepgram.healthy ? 'healthy' : 'unhealthy',
    });
    
    // Log health check metrics
    if (metricsLogger) {
      metricsLogger.logHealthCheck('local', healthStatus.local.healthy, healthStatus.local.latency, healthStatus.local.error);
      metricsLogger.logHealthCheck('deepgram', healthStatus.deepgram.healthy, healthStatus.deepgram.latency, healthStatus.deepgram.error);
    }
    
    return healthStatus;
  } catch (error) {
    console.error("Failed to check ASR health:", error);
    return {
      local: {
        healthy: false,
        error: error instanceof Error ? error.message : 'Unknown error',
        lastChecked: Date.now(),
      },
      deepgram: {
        healthy: false,
        error: error instanceof Error ? error.message : 'Unknown error',
        lastChecked: Date.now(),
      },
    };
  }
});
